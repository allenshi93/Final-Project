---
title: "Grace Mao Allen Shi Final Project"
output: rmarkdown::html_document
runtime: shiny
---

<style type="text/css">
.table {
    width: 40%;
    position: relative;
    left: 7.5%;
}
</style>

<br/><br/>

### Goal
The goal of this project was to scrape professor ratings from ratemyprofessor.com from both Duke and UNC to see if there are any interesting patterns both within and between the school across the numerous departments.

We chose to Duke because as students, we thought this would be interesting to parse. Furthermore, we wanted to do a comparison with our rival, UNC, just for fun. Fortunately, both schools have over 1000 professors with ratings each, which allowed for great analyses.
<br/>


#### Scrape

We were able to produce JSON files for the ratemyprofessor pages that included numerous key variables such as department and rating. Since the JSON was in a predictable pattern we only scraped the variables of interest and compiled them into neat data frames for both Duke and UNC. 

```{r}
library(rvest)
library(httr)
library(XML)
library(jsonlite)

get_data <- function(school){
  final <- data.frame(NULL)
  
  #we take the first 80 pages for each school
  for (i in 1:80){
    url <- paste0("http://www.ratemyprofessors.com/find/professor/?department&institution=Duke%20University&page=",i,
                  "&query&queryoption=TEACHER&queryBy=schoolId&sid=",school,"&sortBy")

    data<-fromJSON(url)

    dept = NULL
    first_name = NULL
    last_name = NULL
    num_rating = NULL
    rating_class = NULL
    overall_rating = NULL
    
    #there are 20 teacher entries for each page 
    for(k in 1:20){
      dept[k]           = data$professors[[k]][[1]]
      first_name[k]     = data$professors[[k]][[4]]
      last_name[k]      = data$professors[[k]][[6]]
      num_rating[k]     = strtoi(data$professors[[k]][[8]])
      rating_class[k]   = data$professors[[k]][[9]]
      overall_rating[k] = as.numeric(data$professors[[k]][[12]])
    }
    
    #make data frame for page
    temp = data.frame(dept, first_name, last_name, num_rating, rating_class, overall_rating, stringsAsFactors = FALSE)
    #add these rows to total school data frame
    final <- rbind(final, temp)
  }
  #return school data frame 
  return (final)
}

#make data frames for each school
school_data <- lapply(list(Duke=1350, UNC=1232), function(x) get_data(x))
```

### Data cleanup

look at sorted unique list of department names for Duke and UNC to determine if some department categories should be combined

```{r}
school_data$Duke[school_data$Duke$dept == "Art History", ]$dept <- "Art & Art History"
school_data$Duke[school_data$Duke$dept == "Art  Art History", ]$dept <- "Art & Art History"
school_data$Duke[school_data$Duke$dept == "Physical Ed", ]$dept <- "Physical Education"
school_data$Duke[school_data$Duke$dept == "Athletics", ]$dept <- "Physical Education"
school_data$Duke[school_data$Duke$dept == "Women's Studies", ]$dept <- "Womens Studies"

school_data$UNC[school_data$UNC$dept == "Environmental Science", ]$dept <- "Environmental Sci & Eng"
school_data$UNC[school_data$UNC$dept == "Biological Sciences", ]$dept <- "Biology"
school_data$UNC[school_data$UNC$dept == "Physical Ed", ]$dept <- "Physical Education"
school_data$UNC[school_data$UNC$dept == "Exercise  Sport Science", ]$dept <- "Exercise & Sport Science"
school_data$UNC[school_data$UNC$dept == "Art", ]$dept <- "Art & Art History"
school_data$UNC[school_data$UNC$dept == "Art History", ]$dept <- "Art & Art History"
school_data$UNC[school_data$UNC$dept == "Health Policy & Management", ]$dept <- "Health Administration"
school_data$UNC[school_data$UNC$dept == "Piano", ]$dept <- "Music"

```

### Data manipulation

The first thing we did was find the average rating per department. We accomplished this by multiply overall rating per professor by the number of unique ratings the professor got to get the total rating. This accounted for the popularity of individual professors. Then, we divided by total number of ratings across recieved across the department to recieve the department average rating.

Within Duke, we noted that many STEM fields had lower deparment rating, and the higher rated departments tended to by in the humanities and social sciences. At UNC, the trend seemed to be consistent. 

```{r}

duke_dept_avg <- lapply(unique(school_data$Duke$dept), 
                      function(x) 
                        sum(school_data$Duke[school_data$Duke$dept == x, ]$overall_rating * 
                        school_data$Duke[school_data$Duke$dept == x, ]$num_rating)/
                        sum(school_data$Duke[school_data$Duke$dept == x, ]$num_rating))
names(duke_dept_avg) <- unique(school_data$Duke$dept)
duke_dept_avg <- sort(unlist(duke_dept_avg),decreasing=TRUE)
duke_dept_avg

unc_dept_avg <- lapply(unique(school_data$UNC$dept), 
                     function(x) 
                       sum(school_data$UNC[school_data$UNC$dept == x, ]$overall_rating * 
                             school_data$UNC[school_data$UNC$dept == x, ]$num_rating)/
                       sum(school_data$UNC[school_data$UNC$dept == x, ]$num_rating))
names(unc_dept_avg) <- unique(school_data$UNC$dept)
unc_dept_avg<-sort(unlist(unc_dept_avg),decreasing=TRUE)
unc_dept_avg
```

Next, we looked at the number of ratings per department. For both schools it seemed like the more popular departments recieved more reviews. For example, while math isn't the most popular major at Duke, many students across numerous departments have math requirements for their degrees, which explaines why it has so many reviews. Moreover, the number of reviews likely impacted the department ratings we found in the last part. For example, the Jewish Studies department only had 3 total reviews all of which were 5 out of 5. Interestingly, the most reviewed department at UNC was english, which may be related to their own undergraduate requirements.

```{r}
duke_num_ratings <- lapply(unique(school_data$Duke$dept), 
                      function(x) 
                        sum(school_data$Duke[school_data$Duke$dept == x, ]$num_rating))
names(duke_num_ratings) <- unique(school_data$Duke$dept)
duke_num_ratings <- sort(unlist(duke_num_ratings),decreasing=TRUE)
duke_num_ratings

unc_num_ratings <- lapply(unique(school_data$UNC$dept), 
                           function(x) 
                             sum(school_data$UNC[school_data$UNC$dept == x, ]$num_rating))
names(unc_num_ratings) <- unique(school_data$UNC$dept)
unc_num_ratings <- sort(unlist(unc_num_ratings),decreasing=TRUE)
unc_num_ratings
```

Next, we found number of ratings per rating class. The rating class, as provided by ratemyprofessor, were good, average and poor.
The trend is that students tend to give more ratings to the "better" professors, indicating those professors that gave a strong impression were more likely to produce students who voluntarily took the time to give them reviews. We were surprised that the poor performing professors didn't have as many reviews as we had assumed strong emotions toward a professor, in either direction, would've driven up the number of reviews.

```{r}
duke_class_num <- lapply(unique(school_data$Duke$rating_class), 
                           function(x) 
                             sum(school_data$Duke[school_data$Duke$rating_class == x, ]$num_rating))
names(duke_class_num) <- unique(school_data$Duke$rating_class)
duke_class_num <- sort(unlist(duke_class_num),decreasing=TRUE)
duke_class_num

unc_class_num <- lapply(unique(school_data$UNC$rating_class), 
                         function(x) 
                           sum(school_data$UNC[school_data$UNC$rating_class == x, ]$num_rating))
names(unc_class_num) <- unique(school_data$UNC$rating_class)
unc_class_num <- sort(unlist(unc_class_num),decreasing=TRUE)
unc_class_num

```

Here, out of the professors with at least 30 ratings, we looked at the top ten best rated professors at each school. We set a threshold for a minimum number of ratings so that we could compile a list of professors who have generated a lot of student interest. We also took this as a signal that the rating was more likely to be reliable. 
It looks like best rated professors at Duke are in STEM fields and the best rated professors at UNC are in history & humanities. The duke result is surprising given the low average department ratings for many of the STEm fields. This could indicate that these department have a handful of superstar professors whose ratings are being dragged down by a larger population of mediocre to poor professors.

```{r}
valid_duke_profs <- school_data$Duke[school_data$Duke$num_rating >= 30, ]
valid_unc_profs <- school_data$UNC[school_data$UNC$num_rating >= 30, ]
valid_duke_profs[order(-valid_duke_profs[,6]), ][1:10,]
valid_unc_profs[order(-valid_unc_profs[,6]), ][1:10,]
```

Just for fun, we wanted to see what are the most common first name of professors at Duke and UNC. They were basically all names from the bible. 

```{r}
dukenames<-count(school_data$Duke, 'first_name')
dukenames[order(-dukenames[,2]), ][1:10,]
uncnames<-count(school_data$UNC, 'first_name')
uncnames[order(-uncnames[,2]), ][1:10,]
```

### Testing
Lastly, we wanted to make some comparisons between Duke and UNC with statistical tests. We did this with both the mean rating and the number of ratings. While there wasn't significant different average rating, we did find a significant different the average number of reviews each professor recieved in each school. At a 5% significance level, the average number of ratings per professor at Duke was significantly higher than the average number of ratings per professor at UNC (p = .001942). It seems that while students are equally satisfied with the level of instruction at both universities, Duke students are more proactive in rating and reflecting on the value of their instructors.

```{r}
t.test(school_data$Duke$overall_rating, school_data$UNC$overall_rating)
t.test(school_data$Duke$num_rating, school_data$UNC$num_rating) #hey this is significant!
```

